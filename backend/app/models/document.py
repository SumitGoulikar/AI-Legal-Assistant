# backend/app/models/document.py
"""
Document Models
===============
Models for user-uploaded documents and their text chunks.

Document: Metadata about uploaded files (PDF, DOCX, TXT)
DocumentChunk: Text chunks extracted from documents for RAG

The chunking strategy:
- Documents are split into overlapping chunks (~500 chars each)
- Each chunk is embedded and stored in ChromaDB
- Chunks are also stored in PostgreSQL for reference/display
"""

from sqlalchemy import Column, String, Integer, DateTime, ForeignKey, Text, JSON, func, Enum
from sqlalchemy.orm import relationship
import uuid
import enum

from app.database import Base


class DocumentStatus(str, enum.Enum):
    """Status of document processing pipeline."""
    PENDING = "pending"          # Just uploaded, not processed
    PROCESSING = "processing"    # Being processed (text extraction, chunking)
    READY = "ready"              # Ready for queries
    FAILED = "failed"            # Processing failed


class Document(Base):
    """
    Uploaded document metadata.
    
    Stores information about user-uploaded legal documents.
    The actual file is stored on disk; this table stores metadata.
    
    Relationships:
    - owner: The user who uploaded this document
    - chunks: Text chunks extracted from this document
    - chat_sessions: Chat sessions about this document
    """
    
    __tablename__ = "documents"
    
    # ============================================
    # PRIMARY KEY
    # ============================================
    id = Column(
        String(36),
        primary_key=True,
        default=lambda: str(uuid.uuid4()),
        nullable=False,
        index=True
    )
    
    # ============================================
    # FOREIGN KEY - Owner
    # ============================================
    user_id = Column(
        String(36),
        ForeignKey("users.id", ondelete="CASCADE"),
        nullable=False,
        index=True,
        comment="ID of user who uploaded this document"
    )
    
    # ============================================
    # FILE METADATA
    # ============================================
    filename = Column(
        String(255),
        nullable=False,
        comment="Stored filename (UUID-based)"
    )
    
    original_name = Column(
        String(255),
        nullable=False,
        comment="Original filename uploaded by user"
    )
    
    file_type = Column(
        String(50),
        nullable=False,
        comment="File extension: pdf, docx, txt"
    )
    
    file_size = Column(
        Integer,
        nullable=False,
        comment="File size in bytes"
    )
    
    file_path = Column(
        String(500),
        nullable=False,
        comment="Path to stored file"
    )
    
    # ============================================
    # PROCESSING STATUS
    # ============================================
    status = Column(
        String(20),
        default=DocumentStatus.PENDING.value,
        nullable=False,
        index=True,
        comment="Processing status: pending, processing, ready, failed"
    )
    
    error_message = Column(
        Text,
        nullable=True,
        comment="Error message if processing failed"
    )
    
    # ============================================
    # PROCESSING RESULTS
    # ============================================
    chunk_count = Column(
        Integer,
        default=0,
        nullable=False,
        comment="Number of text chunks extracted"
    )
    
    page_count = Column(
        Integer,
        nullable=True,
        comment="Number of pages (for PDFs)"
    )
    
    word_count = Column(
        Integer,
        nullable=True,
        comment="Approximate word count"
    )
    
    # Document summary (generated by AI)
    summary = Column(
        Text,
        nullable=True,
        comment="AI-generated document summary"
    )
    
    # ============================================
    # TIMESTAMPS
    # ============================================
    created_at = Column(
        DateTime(timezone=True),
        server_default=func.now(),
        nullable=False
    )
    
    processed_at = Column(
        DateTime(timezone=True),
        nullable=True,
        comment="When processing completed"
    )
    
    # ============================================
    # RELATIONSHIPS
    # ============================================
    owner = relationship(
        "User",
        back_populates="documents"
    )
    
    chunks = relationship(
        "DocumentChunk",
        back_populates="document",
        cascade="all, delete-orphan",
        lazy="selectin"
    )
    
    chat_sessions = relationship(
        "ChatSession",
        back_populates="document",
        lazy="selectin"
    )
    
    # ============================================
    # METHODS
    # ============================================
    def __repr__(self) -> str:
        return f"<Document(id={self.id}, name={self.original_name}, status={self.status})>"
    
    def to_dict(self) -> dict:
        return {
            "id": self.id,
            "user_id": self.user_id,
            "original_name": self.original_name,
            "file_type": self.file_type,
            "file_size": self.file_size,
            "status": self.status,
            "chunk_count": self.chunk_count,
            "page_count": self.page_count,
            "word_count": self.word_count,
            "summary": self.summary,
            "created_at": self.created_at.isoformat() if self.created_at else None,
            "processed_at": self.processed_at.isoformat() if self.processed_at else None,
        }


class DocumentChunk(Base):
    """
    Text chunk extracted from a document.
    
    Documents are split into chunks for:
    - Efficient embedding and retrieval (RAG)
    - Providing source references in answers
    - Fitting within LLM context windows
    
    The actual embeddings are stored in ChromaDB (vector store).
    This table stores the text content and metadata for reference.
    """
    
    __tablename__ = "document_chunks"
    
    # ============================================
    # PRIMARY KEY
    # ============================================
    id = Column(
        String(36),
        primary_key=True,
        default=lambda: str(uuid.uuid4()),
        nullable=False,
        index=True
    )
    
    # ============================================
    # FOREIGN KEY - Document
    # ============================================
    document_id = Column(
        String(36),
        ForeignKey("documents.id", ondelete="CASCADE"),
        nullable=False,
        index=True
    )
    
    # ============================================
    # CHUNK DATA
    # ============================================
    chunk_index = Column(
        Integer,
        nullable=False,
        comment="Position of chunk in document (0-indexed)"
    )
    
    content = Column(
        Text,
        nullable=False,
        comment="The actual text content of this chunk"
    )
    
    # ============================================
    # LOCATION METADATA
    # ============================================
    start_char = Column(
        Integer,
        nullable=True,
        comment="Starting character position in original document"
    )
    
    end_char = Column(
        Integer,
        nullable=True,
        comment="Ending character position in original document"
    )
    
    start_page = Column(
        Integer,
        nullable=True,
        comment="Starting page number (1-indexed, for PDFs)"
    )
    
    end_page = Column(
        Integer,
        nullable=True,
        comment="Ending page number (for chunks spanning pages)"
    )
    
    # ============================================
    # EMBEDDING REFERENCE
    # ============================================
    # The actual embedding vector is stored in ChromaDB
    # This ID links to the ChromaDB entry
    chroma_id = Column(
        String(100),
        nullable=True,
        index=True,
        comment="ID in ChromaDB vector store"
    )
    
    # ============================================
    # ADDITIONAL METADATA
    # ============================================
    extra_metadata = Column("metadata",
        JSON,
        nullable=True,
        comment="Additional metadata (headers, formatting, etc.)"
    )
    
    # ============================================
    # TIMESTAMPS
    # ============================================
    created_at = Column(
        DateTime(timezone=True),
        server_default=func.now(),
        nullable=False
    )
    
    # ============================================
    # RELATIONSHIPS
    # ============================================
    document = relationship(
        "Document",
        back_populates="chunks"
    )
    
    # ============================================
    # METHODS
    # ============================================
    def __repr__(self) -> str:
        return f"<DocumentChunk(id={self.id}, doc_id={self.document_id}, index={self.chunk_index})>"
    
    def to_dict(self) -> dict:
        return {
            "id": self.id,
            "document_id": self.document_id,
            "chunk_index": self.chunk_index,
            "content": self.content,
            "start_page": self.start_page,
            "end_page": self.end_page,
            "created_at": self.created_at.isoformat() if self.created_at else None,
        }